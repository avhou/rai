
@article{europe1,
	title = {Tackling deepfakes in {European} policy},
	language = {en},
	urldate = {2024-03-24},
	author = {Rachel, MANIRAMBONA},
	file = {Rachel - Tackling deepfakes in European policy.pdf:/Users/alexander/Zotero/storage/YSLJIS6E/Rachel - Tackling deepfakes in European policy.pdf:application/pdf},
}

@misc{vrt1,
	title = {{CHECK} - {Alweer} {VRT}-gezichten misbruikt in valse nieuwsberichten: zo herken je online oplichting},
	shorttitle = {{CHECK} - {Alweer} {VRT}-gezichten misbruikt in valse nieuwsberichten},
	url = {https://www.vrt.be/vrtnws/nl/2024/03/08/check-alweer-vrt-gezichten-in-online-scams-misbruikt-hoe-herk/},
	language = {nl},
	urldate = {2024-03-24},
	journal = {vrtnws.be},
	author = {NWS, VRT},
	file = {Snapshot:/Users/alexander/Zotero/storage/A4ZGPGIA/check-alweer-vrt-gezichten-in-online-scams-misbruikt-hoe-herk.html:text/html},
}

@misc{vrt2,
	title = {{CHECK} - {Opgepast} voor valse {AI}-reportage met {VRT} {NWS}-anker {Annelies} {Van} {Herck} over spel waar je geld mee zou verdienen},
	url = {https://www.vrt.be/vrtnws/nl/2024/01/16/deepfake-reclame-game/},
	language = {nl},
	urldate = {2024-03-24},
	journal = {vrtnws.be},
	author = {NWS, VRT},
	file = {Snapshot:/Users/alexander/Zotero/storage/HE6W6VPW/deepfake-reclame-game.html:text/html},
}

@misc{meta,
	title = {Enforcing {Against} {Manipulated} {Media}},
	url = {https://about.fb.com/news/2020/01/enforcing-against-manipulated-media/},
	abstract = {We're strengthening our policy toward misleading manipulated videos that have been identified as deepfakes.},
	language = {en-US},
	urldate = {2024-03-24},
	journal = {Meta},
	month = jan,
	year = {2020},
	file = {Snapshot:/Users/alexander/Zotero/storage/BBXGL3PL/enforcing-against-manipulated-media.html:text/html},
}

@misc{google,
	title = {How we're helping creators disclose altered or synthetic content},
	url = {https://blog.google/intl/en-in/products/platforms/how-were-helping-creators-disclose-altered-or-synthetic-content/},
	abstract = {Generative AI is transforming the ways creators express themselves – from storyboarding ideas to experimenting with tools that enhance the creative process. But viewers …},
	language = {en-in},
	urldate = {2024-03-24},
	journal = {Google},
	month = mar,
	year = {2024},
	file = {Snapshot:/Users/alexander/Zotero/storage/FUYCT7V2/how-were-helping-creators-disclose-altered-or-synthetic-content.html:text/html},
}

@inproceedings{scholar2,
	title = {A {Novel} {Machine} {Learning} based {Method} for {Deepfake} {Video} {Detection} in {Social} {Media}},
	url = {https://ieeexplore.ieee.org/abstract/document/9426086},
	doi = {10.1109/iSES50453.2020.00031},
	abstract = {With the advent of deepfake videos, video forgery has become a serious threat. Videos in social media are the most common and serious targets. There are some existing works for detecting deepfake videos but very few attempts have been made for videos in social media. This paper presents a neural network based method to detect fake videos. A model, consisting of a convolutional neural network (CNN) and a classifier network is proposed. Three different structures, XceptionNet, InceptionV3 and Resnet50 have been considered as the CNN modules and a comparative study has been made. Xception Net has been chosen in the proposed model and paired with the proposed classifier for classification. We used the FaceForensics++ dataset to reach the best model. Our model integrated in the algorithm detects compressed videos in social media.},
	urldate = {2024-03-23},
	booktitle = {2020 {IEEE} {International} {Symposium} on {Smart} {Electronic} {Systems} ({iSES}) ({Formerly} {iNiS})},
	author = {Mitra, Alakananda and Mohanty, Saraju P. and Corcoran, Peter and Kougianos, Elias},
	month = dec,
	year = {2020},
	keywords = {Machine learning, Neural networks, Classification algorithms, Compressed Video., Convolutional Neural Network (CNN), Convolutional neural networks, Deep Learning, Deepfake, Depthwise Separable Convolution, Forgery, Machine learning algorithms, Social Media, Social networking (online), Transfer Learning},
	pages = {91--96},
	file = {IEEE Xplore Abstract Record:/Users/alexander/Zotero/storage/BRNANG67/9426086.html:text/html},
}

@article{scholar3,
	title = {Deep {Fake} {Video} {Detection} {Using} {Transfer} {Learning} {Approach}},
	volume = {48},
	issn = {2191-4281},
	url = {https://doi.org/10.1007/s13369-022-07321-3},
	doi = {10.1007/s13369-022-07321-3},
	abstract = {The usage of the internet as a fast medium for spreading fake news reinforces the requirement of computational utensils in order to fight for it. Fake videos also called deep fakes that create great intimidation in society in an assortment of social and political behaviour. It can also be utilized for malevolent intentions. Owing to the availability of deep fake generation algorithms at cheap computation power in cloud platforms, realistic fake videos or images are created. However, it is more critical to detect fake content because of the increased complexity of leveraging various approaches to smudge the tampering. Therefore, this work proposes a novel framework to detect fake videos through the utilization of transfer learning in autoencoders and a hybrid model of convolutional neural networks (CNN) and Recurrent neural networks (RNN). Unseen test input data are investigated to check the generalizability of the model. Also, the effect of residual image input on accuracy of the model is analyzed. Results are presented for both, with and without transfer learning to validate the effectiveness of transfer learning.},
	language = {en},
	number = {8},
	urldate = {2024-03-23},
	journal = {Arabian Journal for Science and Engineering},
	author = {Suratkar, Shraddha and Kazi, Faruk},
	month = aug,
	year = {2023},
	keywords = {Autoencoders, Convolutional neural networks (CNN), Deep fake detection, Recurrent neural networks (RNN), Residual images, Transfer learning},
	pages = {9727--9737},
	file = {Full Text PDF:/Users/alexander/Zotero/storage/GVJRZXQW/Suratkar and Kazi - 2023 - Deep Fake Video Detection Using Transfer Learning .pdf:application/pdf},
}

@misc{capture,
	title = {\textit{{The} {Capture}} ({TV} series)},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=The_Capture_(TV_series)&oldid=1213822347},
	abstract = {The Capture is a British mystery thriller television series created, written and directed by Ben Chanan, and starring Holliday Grainger, Callum Turner, Laura Haddock, Ben Miles, Cavan Clerkin, Paul Ritter, and Ron Perlman.
The series premiered on BBC One on 3 September 2019, and received positive reviews from critics. It was announced in June 2020 that a second series had been commissioned. The second series began airing on BBC One in the UK on 28 August 2022 and it also premiered on Peacock in the US on 3 November 2022.},
	language = {en},
	urldate = {2024-03-24},
	journal = {Wikipedia},
	month = mar,
	year = {2024},
	note = {Page Version ID: 1213822347},
	file = {Snapshot:/Users/alexander/Zotero/storage/7ZAFCD58/The_Capture_(TV_series).html:text/html},
}

@article{scholar1,
	title = {The {Emergence} of {Deepfake} {Technology}: {A} {Review}},
	volume = {9},
	issn = {1927-0321},
	shorttitle = {The {Emergence} of {Deepfake} {Technology}},
	doi = {http://doi.org/10.22215/timreview/1282},
	number = {11},
	urldate = {2024-03-24},
	journal = {Technology Innovation Management Review},
	author = {Westerlund, Mika},
	year = {2019},
	note = {Place: Ottawa
Publisher: Talent First Network},
	pages = {40--53},
	file = {Full Text:/Users/alexander/Zotero/storage/KIW27SUD/Westerlund - 2019 - The Emergence of Deepfake Technology A Review.pdf:application/pdf;The Emergence of Deepfake Technology\: A Review | TIM Review:/Users/alexander/Zotero/storage/I4LDUVTL/1282.html:text/html},
}

@inproceedings{facedataset,
	title = {{FaceForensics}++: {Learning} to {Detect} {Manipulated} {Facial} {Images}},
	shorttitle = {{FaceForensics}++},
	url = {https://openaccess.thecvf.com/content_ICCV_2019/html/Rossler_FaceForensics_Learning_to_Detect_Manipulated_Facial_Images_ICCV_2019_paper.html},
	urldate = {2024-03-23},
	author = {Rossler, Andreas and Cozzolino, Davide and Verdoliva, Luisa and Riess, Christian and Thies, Justus and Niessner, Matthias},
	year = {2019},
	pages = {1--11},
	file = {Full Text PDF:/Users/alexander/Zotero/storage/J48Y55TM/Rossler et al. - 2019 - FaceForensics++ Learning to Detect Manipulated Fa.pdf:application/pdf},
}

@misc{vrt,
	title = {{VRT} {NWS}: nieuws},
	shorttitle = {{VRT} {NWS}},
	url = {https://www.vrt.be/vrtnws/nl/},
	abstract = {Het VRT NWS nieuws: betrouwbaar, helder en prikkelend. Het biedt je tekst, beeld en audio gebundeld in rubrieken en dossiers, met extra duiding door onze experten.},
	language = {nl},
	urldate = {2024-03-24},
	journal = {VRTNWS},
	author = {NWS, VRT},
	month = mar,
	year = {2024},
}

@book{europol1,
	address = {LU},
	title = {Facing reality?: law enforcement and the challenge of deepfakes : an observatory report from the {Europol} innovation lab.},
	shorttitle = {Facing reality?},
	url = {https://data.europa.eu/doi/10.2813/158794},
	language = {en},
	urldate = {2024-03-24},
	publisher = {Publications Office},
	author = {{European Union Agency for Law Enforcement Cooperation.}},
	year = {2024},
	file = {European Union Agency for Law Enforcement Cooperation. - 2024 - Facing reality law enforcement and the challenge.pdf:/Users/alexander/Zotero/storage/KYM7NP2F/European Union Agency for Law Enforcement Cooperation. - 2024 - Facing reality law enforcement and the challenge.pdf:application/pdf},
}

@misc{aiact,
	title = {{EU} {Artificial} {Intelligence} {Act} {\textbar} {Up}-to-date developments and analyses of the {EU} {AI} {Act}},
	url = {https://artificialintelligenceact.eu/},
	language = {en-US},
	urldate = {2024-03-24},
	file = {Snapshot:/Users/alexander/Zotero/storage/9XTPT9C5/artificialintelligenceact.eu.html:text/html},
}

@misc{china,
	title = {China’s {AI} {Regulations} and {How} {They} {Get} {Made}},
	url = {https://carnegieendowment.org/2023/07/10/china-s-ai-regulations-and-how-they-get-made-pub-90117},
	abstract = {Beijing is leading the way in AI regulation, releasing groundbreaking new strategies to govern algorithms, chatbots, and more. Global partners need a better understanding of what, exactly, this regulation entails, what it says about China’s AI priorities, and what lessons other AI regulators can learn.},
	language = {en},
	urldate = {2024-03-24},
	journal = {Carnegie Endowment for International Peace},
	author = {Sheehan, Matt},
}

@article{ass1,
	title = {Deepfakes generation and detection: state-of-the-art, open challenges, countermeasures, and way forward},
	volume = {53},
	issn = {1573-7497},
	shorttitle = {Deepfakes generation and detection},
	url = {https://doi.org/10.1007/s10489-022-03766-z},
	doi = {10.1007/s10489-022-03766-z},
	abstract = {Easy access to audio-visual content on social media, combined with the availability of modern tools such as Tensorflow or Keras, and open-source trained models, along with economical computing infrastructure, and the rapid evolution of deep-learning (DL) methods have heralded a new and frightening trend. Particularly, the advent of easily available and ready to use Generative Adversarial Networks (GANs), have made it possible to generate deepfakes media partially or completely fabricated with the intent to deceive to disseminate disinformation and revenge porn, to perpetrate financial frauds and other hoaxes, and to disrupt government functioning. Existing surveys have mainly focused on the detection of deepfake images and videos; this paper provides a comprehensive review and detailed analysis of existing tools and machine learning (ML) based approaches for deepfake generation, and the methodologies used to detect such manipulations in both audio and video. For each category of deepfake, we discuss information related to manipulation approaches, current public datasets, and key standards for the evaluation of the performance of deepfake detection techniques, along with their results. Additionally, we also discuss open challenges and enumerate future directions to guide researchers on issues which need to be considered in order to improve the domains of both deepfake generation and detection. This work is expected to assist readers in understanding how deepfakes are created and detected, along with their current limitations and where future research may lead.},
	language = {en},
	number = {4},
	urldate = {2024-04-03},
	journal = {Applied Intelligence},
	author = {Masood, Momina and Nawaz, Mariam and Malik, Khalid Mahmood and Javed, Ali and Irtaza, Aun and Malik, Hafiz},
	month = feb,
	year = {2023},
	keywords = {Deep learning, Artificial intelligence, Deepfakes, Face swap, Lip-synching, Puppetmaster, Speech synthesis, Voice conversion},
	pages = {3974--4026},
	file = {Submitted Version:/Users/alexander/Zotero/storage/8AH7YXFY/Masood et al. - 2023 - Deepfakes generation and detection state-of-the-a.pdf:application/pdf},
}

@article{ass2,
	title = {The {Creation} and {Detection} of {Deepfakes}: {A} {Survey}},
	volume = {54},
	issn = {0360-0300},
	shorttitle = {The {Creation} and {Detection} of {Deepfakes}},
	url = {https://doi.org/10.1145/3425780},
	doi = {10.1145/3425780},
	abstract = {Generative deep learning algorithms have progressed to a point where it is difficult to tell the difference between what is real and what is fake. In 2018, it was discovered how easy it is to use this technology for unethical and malicious applications, such as the spread of misinformation, impersonation of political leaders, and the defamation of innocent individuals. Since then, these “deepfakes” have advanced significantly. In this article, we explore the creation and detection of deepfakes and provide an in-depth view as to how these architectures work. The purpose of this survey is to provide the reader with a deeper understanding of (1) how deepfakes are created and detected, (2) the current trends and advancements in this domain, (3) the shortcomings of the current defense solutions, and (4) the areas that require further research and attention.},
	number = {1},
	urldate = {2024-04-03},
	journal = {ACM Computing Surveys},
	author = {Mirsky, Yisroel and Lee, Wenke},
	month = jan,
	year = {2021},
	keywords = {Deepfake, deep fake, face swap, generative AI, impersonation, reenactment, replacement, social engineering},
	pages = {7:1--7:41},
	file = {Submitted Version:/Users/alexander/Zotero/storage/C4TAK6A2/Mirsky and Lee - 2021 - The Creation and Detection of Deepfakes A Survey.pdf:application/pdf},
}

@misc{ars,
	title = {Meta relaxes “incoherent” policy requiring removal of {AI} videos},
	url = {https://arstechnica.com/tech-policy/2024/04/meta-relaxes-incoherent-policy-requiring-removal-of-ai-videos/},
	abstract = {Meta will stop removing harmless AI videos in July.},
	language = {en-us},
	urldate = {2024-04-06},
	journal = {Ars Technica},
	author = {Belanger, Ashley},
	month = apr,
	year = {2024},
	file = {Snapshot:/Users/alexander/Zotero/storage/F7X5XMQ9/meta-relaxes-incoherent-policy-requiring-removal-of-ai-videos.html:text/html},
}
